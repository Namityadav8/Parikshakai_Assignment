{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Creation using Web Scraping\n"
      ],
      "metadata": {
        "id": "de2pXgUbJW9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKYQ5fA1GL5L",
        "outputId": "f3907e10-5ec3-4a80-9c24-c5ecc52be7d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> scraping: https://www.indeed.com/q-data-scientist-jobs.html\n",
            "Hmm, got status: 403 for https://www.indeed.com/q-data-scientist-jobs.html\n",
            ">>> scraping: https://www.glassdoor.com/Interview/data-scientist-interview-questions-SRCH_KO0,14.htm\n",
            "Hmm, got status: 403 for https://www.glassdoor.com/Interview/data-scientist-interview-questions-SRCH_KO0,14.htm\n",
            ">>> scraping: https://towardsdatascience.com/\n",
            ">>> scraping: https://www.naukri.com/data-scientist-jobs\n",
            ">>> scraping: https://www.analyticsvidhya.com/blog/\n",
            "Got 54 usable samples\n",
            "Saved to raw_text_samples.csv (hopefully works!)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time, random   # just lumped them together for no reason\n",
        "\n",
        "# quick helper to fetch page content (note: might need retries later?)\n",
        "def fetch_html(url):\n",
        "    try:\n",
        "        resp = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        if resp.status_code == 200:\n",
        "            return resp.text\n",
        "        else:\n",
        "            print(\"Hmm, got status:\", resp.status_code, \"for\", url)\n",
        "            return None\n",
        "    except Exception as err:\n",
        "        # generic catch, not the best but works for now\n",
        "        print(f\"Problem reaching {url} -> {err}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# not sure if we need class filter everywhere, but let's keep it here\n",
        "def grab_text_bits(page_html, tag=\"p\", css_class=None):\n",
        "    soup = BeautifulSoup(page_html, \"html.parser\")\n",
        "\n",
        "    if css_class:\n",
        "        found = soup.find_all(tag, class_=css_class)\n",
        "    else:\n",
        "        found = soup.find_all(tag)\n",
        "\n",
        "    results = []\n",
        "    for f in found:\n",
        "        txt = f.get_text(strip=True)\n",
        "        # don’t keep super short junk\n",
        "        if len(txt.split()) > 5:\n",
        "            results.append(txt)\n",
        "    return results\n",
        "\n",
        "\n",
        "# a few sites I thought of scraping (probably should rotate later?)\n",
        "pages_to_scrape = [\n",
        "    \"https://www.indeed.com/q-data-scientist-jobs.html\",\n",
        "    \"https://www.glassdoor.com/Interview/data-scientist-interview-questions-SRCH_KO0,14.htm\",\n",
        "    \"https://towardsdatascience.com/\",\n",
        "    \"https://www.naukri.com/data-scientist-jobs\",\n",
        "    \"https://www.analyticsvidhya.com/blog/\"\n",
        "]\n",
        "\n",
        "# collected texts go here\n",
        "scraped_texts = []\n",
        "\n",
        "# main scraping loop\n",
        "for site in pages_to_scrape:\n",
        "    print(\">>> scraping:\", site)\n",
        "    html_code = fetch_html(site)\n",
        "\n",
        "    if html_code:\n",
        "        snippets = grab_text_bits(html_code, \"p\")  # might change tag later\n",
        "        for s in snippets:\n",
        "            scraped_texts.append(s)  # could have just extended, but meh\n",
        "\n",
        "    # little pause so we don't hammer servers\n",
        "    wait_time = random.randint(2, 6)   # added +1 sec just in case\n",
        "    time.sleep(wait_time)\n",
        "\n",
        "# cleanup: unique-ify results (keeping order kinda lost but whatever)\n",
        "unique_bits = list(set(scraped_texts))\n",
        "\n",
        "# only keep the first ~60-ish, otherwise too many\n",
        "trimmed_bits = unique_bits[:60]\n",
        "\n",
        "print(\"Got\", len(trimmed_bits), \"usable samples\")\n",
        "\n",
        "# write to CSV file\n",
        "with open(\"raw_text_samples.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as fh:\n",
        "    csv_writer = csv.writer(fh)\n",
        "    csv_writer.writerow([\"sample_text\"])   # changed header name slightly\n",
        "    for row in trimmed_bits:\n",
        "        csv_writer.writerow([row])\n",
        "\n",
        "print(\"Saved to raw_text_samples.csv (hopefully works!)\")\n",
        "\n",
        "# TODO: maybe later add better error handling for sites that block us\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"raw_text_samples.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KsgDyFUFHPAK",
        "outputId": "f3cb3dbd-33e9-486b-a151-9446ee519586"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fff1137d-eba1-4404-9395-15884f3a35a8\", \"raw_text_samples.csv\", 5078)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning\n"
      ],
      "metadata": {
        "id": "gKcRPQEhJS9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "def clean_line(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"<.*?>\", \"\", t)        # strip HTML tags\n",
        "    t = t.lower()                      # lowercase\n",
        "    t = re.sub(r\"[^a-z0-9.,!?;:'\\\"()\\s-]\", \" \", t)  # remove weird symbols\n",
        "    t = re.sub(r\"\\s+\", \" \", t)         # collapse spaces\n",
        "    return t.strip()\n",
        "\n",
        "raw_rows = []\n",
        "with open(\"raw_text_samples.csv\", \"r\", encoding=\"utf-8\") as infile:\n",
        "    reader = csv.DictReader(infile)\n",
        "\n",
        "    # get the actual column names in the file\n",
        "    print(\"CSV headers found:\", reader.fieldnames)\n",
        "\n",
        "    # pick the first column if we’re unsure\n",
        "    col_name = reader.fieldnames[0]\n",
        "\n",
        "    for row in reader:\n",
        "        raw_rows.append(row[col_name])\n",
        "\n",
        "print(f\"Loaded {len(raw_rows)} raw samples\")\n",
        "\n",
        "# clean + dedup\n",
        "seen, cleaned_rows = set(), []\n",
        "for r in raw_rows:\n",
        "    cleaned = clean_line(r)\n",
        "    if len(cleaned.split()) < 4:\n",
        "        continue\n",
        "    if cleaned and cleaned not in seen:\n",
        "        cleaned_rows.append(cleaned)\n",
        "        seen.add(cleaned)\n",
        "\n",
        "print(f\"After cleaning: {len(cleaned_rows)} samples remain\")\n",
        "\n",
        "# save cleaned TXT\n",
        "with open(\"cleaned_samples.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
        "    for cl in cleaned_rows:\n",
        "        f_out.write(cl + \"\\n\")\n",
        "\n",
        "# save cleaned CSV\n",
        "with open(\"cleaned_samples.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
        "    writer = csv.writer(f_out)\n",
        "    writer.writerow([\"cleaned_text\"])\n",
        "    for cl in cleaned_rows:\n",
        "        writer.writerow([cl])\n",
        "\n",
        "print(\"✅ Cleaned files saved: cleaned_samples.txt & cleaned_samples.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJyZ9xgCHVks",
        "outputId": "e7a1ded0-42f4-49c9-e1c9-9b5019cdc580"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV headers found: ['sample_text']\n",
            "Loaded 54 raw samples\n",
            "After cleaning: 54 samples remain\n",
            "✅ Cleaned files saved: cleaned_samples.txt & cleaned_samples.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is done to download the cleaned dataset files\n",
        "from google.colab import files\n",
        "files.download(\"cleaned_samples.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "43pEKA7NIyQI",
        "outputId": "c51073e6-3455-4ae0-df3c-1f086b2dffb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4c0c8133-74fa-42df-af87-1ec410b7376c\", \"cleaned_samples.csv\", 5029)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Annotation"
      ],
      "metadata": {
        "id": "jqx-PG64Ji_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- simple rule-based annotation function ---\n",
        "def annotate_text(text):\n",
        "    t = text.lower()\n",
        "\n",
        "    # Category detection\n",
        "    if \"interview\" in t or \"question\" in t or \"answer\" in t:\n",
        "        category = \"Interview Question\"\n",
        "    elif \"apply\" in t or \"responsibilities\" in t or \"requirements\" in t or \"role\" in t:\n",
        "        category = \"Job Description\"\n",
        "    else:\n",
        "        category = \"Blog/Article\"\n",
        "\n",
        "    # Skill tagging (quick keyword scan)\n",
        "    skills = []\n",
        "    for skill in [\"python\", \"sql\", \"machine learning\", \"statistics\", \"nlp\", \"deep learning\", \"excel\", \"r \"]:\n",
        "        if skill in t:\n",
        "            skills.append(skill)\n",
        "    skill_tag = \", \".join(skills) if skills else \"General\"\n",
        "\n",
        "    # Difficulty estimation (rough heuristics)\n",
        "    if any(word in t for word in [\"introduction\", \"basics\", \"beginner\", \"simple\"]):\n",
        "        difficulty = \"Beginner\"\n",
        "    elif any(word in t for word in [\"optimize\", \"deployment\", \"scalable\", \"production\", \"pipeline\"]):\n",
        "        difficulty = \"Advanced\"\n",
        "    else:\n",
        "        difficulty = \"Intermediate\"\n",
        "\n",
        "    return category, skill_tag, difficulty\n",
        "\n",
        "\n",
        "# --- use the correct full path ---\n",
        "input_file = \"/content/cleaned_samples.csv\"\n",
        "\n",
        "cleaned_rows = []\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as infile:\n",
        "    reader = csv.DictReader(infile)\n",
        "    # auto-detect the text column\n",
        "    text_col = reader.fieldnames[0]\n",
        "    print(\"Using column:\", text_col)\n",
        "    for row in reader:\n",
        "        cleaned_rows.append(row[text_col])\n",
        "\n",
        "print(f\"Loaded {len(cleaned_rows)} cleaned samples\")\n",
        "\n",
        "\n",
        "# --- annotate only first 20 for demo ---\n",
        "sample_rows = cleaned_rows[:20]\n",
        "\n",
        "annotated = []\n",
        "for r in sample_rows:\n",
        "    cat, skill, diff = annotate_text(r)\n",
        "    annotated.append({\n",
        "        \"text\": r,\n",
        "        \"category\": cat,\n",
        "        \"skill_tag\": skill,\n",
        "        \"difficulty\": diff\n",
        "    })\n",
        "\n",
        "\n",
        "os.makedirs(\"/mnt/data\", exist_ok=True)\n",
        "\n",
        "# --- save annotated dataset to CSV ---\n",
        "csv_output = \"/mnt/data/annotated_samples.csv\"\n",
        "with open(csv_output, \"w\", encoding=\"utf-8\", newline=\"\") as out_csv:\n",
        "    writer = csv.DictWriter(out_csv, fieldnames=[\"text\", \"category\", \"skill_tag\", \"difficulty\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(annotated)\n",
        "\n",
        "# --- save also to JSON ---\n",
        "json_output = \"/mnt/data/annotated_samples.json\"\n",
        "with open(json_output, \"w\", encoding=\"utf-8\") as out_json:\n",
        "    json.dump(annotated, out_json, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"✅ Saved 20 annotated rows into:\")\n",
        "print(\"CSV:\", csv_output)\n",
        "print(\"JSON:\", json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phoerhjhJg1X",
        "outputId": "bcd4d6b4-12c3-4894-b9b9-7663c5a7ece8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using column: cleaned_text\n",
            "Loaded 54 cleaned samples\n",
            "✅ Saved 20 annotated rows into:\n",
            "CSV: /mnt/data/annotated_samples.csv\n",
            "JSON: /mnt/data/annotated_samples.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Annotated Files"
      ],
      "metadata": {
        "id": "Y16lOe3fV2Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First this is for downloading csv files\n",
        "from google.colab import files\n",
        "files.download(csv_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KPPByQQgV7gP",
        "outputId": "16e4d9c8-948b-41b0-f0cf-e12a8f330070"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6022df3e-9146-4ee5-9d3d-4f40660a789c\", \"annotated_samples.csv\", 2686)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for downloading json files\n",
        "from google.colab import files\n",
        "files.download(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Mvfs5_DGWIo2",
        "outputId": "43c4625f-1829-4480-dc21-015b94d8014e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f512d8d-a59f-4a42-9cb2-3d144fe1fff0\", \"annotated_samples.json\", 4266)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}